{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/py27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "from keras import backend as K\n",
    "import datetime\n",
    "K.clear_session()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "with open ('../params.json') as f:\n",
    "    params = json.load(f)\n",
    "    \n",
    "table_prefix = params['table_prefix']\n",
    "diseases = params['diseases']\n",
    "case_limit = params['case_limit']\n",
    "control_limit = params['control_limit']\n",
    "min_enrollment = params['enrollment']\n",
    "user = params['user']\n",
    "\n",
    "chunk = True\n",
    "\n",
    "\n",
    "# run_id = table_prefix_ + str(case_limit) + '_' + datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "# print(run_id)\n",
    "\n",
    "creds_file = \"/home/\" + user + \"/creds.txt\" \n",
    "creds = lines = [line.rstrip('\\n') for line in open(creds_file)]\n",
    "\n",
    "connection_string = (\"Driver={ODBC Driver 17 for SQL Server};\" + \n",
    "                     \"server=\" + creds[0] + \";\" +\n",
    "                     \"domain=\" + creds[1] + \";\" +  \n",
    "                     \"database=\" + creds[2] + \";\" +\n",
    "                     \"uid=\" + creds[3]  + \";\" +\n",
    "                     \"pwd=\" + creds[4] + \";\" +\n",
    "                     \"ssl=require;\")\n",
    "\n",
    "cn = pyodbc.connect(connection_string, autocommit=True)\n",
    "cursor = cn.cursor()\n",
    "\n",
    "directory = '../../data/diseaes_replaced' + str(table_prefix) + '_' + str(case_limit)\n",
    "output_dir = '../../outputs/' + str(table_prefix) + _ + str(case_limit) + '_' +\\\n",
    "             'gd'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "def get_data(path):\n",
    "    ''' Returns dataframe with columns: 'path', 'word'.'''\n",
    "    datadir = Path(path)\n",
    "    files = [(str(f), f.parts[-1]) for f in datadir.glob('*.csv.gz') if f]\n",
    "    df = pd.DataFrame(files, columns=['path', 'word'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       ../../data/diseaes_replacedtest_10000/seq_1842...\n",
      "1       ../../data/diseaes_replacedtest_10000/seq_1734...\n",
      "2       ../../data/diseaes_replacedtest_10000/seq_1151...\n",
      "3       ../../data/diseaes_replacedtest_10000/seq_1865...\n",
      "4       ../../data/diseaes_replacedtest_10000/seq_1788...\n",
      "5       ../../data/diseaes_replacedtest_10000/seq_8770...\n",
      "6       ../../data/diseaes_replacedtest_10000/seq_8740...\n",
      "7       ../../data/diseaes_replacedtest_10000/seq_1540...\n",
      "8       ../../data/diseaes_replacedtest_10000/seq_8500...\n",
      "9       ../../data/diseaes_replacedtest_10000/seq_1131...\n",
      "10      ../../data/diseaes_replacedtest_10000/seq_3560...\n",
      "11      ../../data/diseaes_replacedtest_10000/seq_1888...\n",
      "12      ../../data/diseaes_replacedtest_10000/seq_1666...\n",
      "13      ../../data/diseaes_replacedtest_10000/seq_5430...\n",
      "14      ../../data/diseaes_replacedtest_10000/seq_1964...\n",
      "15      ../../data/diseaes_replacedtest_10000/seq_7350...\n",
      "16      ../../data/diseaes_replacedtest_10000/seq_1196...\n",
      "17      ../../data/diseaes_replacedtest_10000/seq_1326...\n",
      "18      ../../data/diseaes_replacedtest_10000/seq_1227...\n",
      "19      ../../data/diseaes_replacedtest_10000/seq_1741...\n",
      "20      ../../data/diseaes_replacedtest_10000/seq_1170...\n",
      "21      ../../data/diseaes_replacedtest_10000/seq_2920...\n",
      "22      ../../data/diseaes_replacedtest_10000/seq_1306...\n",
      "23      ../../data/diseaes_replacedtest_10000/seq_5980...\n",
      "24      ../../data/diseaes_replacedtest_10000/seq_1859...\n",
      "25      ../../data/diseaes_replacedtest_10000/seq_5170...\n",
      "26      ../../data/diseaes_replacedtest_10000/seq_1343...\n",
      "27      ../../data/diseaes_replacedtest_10000/seq_1960...\n",
      "28      ../../data/diseaes_replacedtest_10000/seq_2550...\n",
      "29      ../../data/diseaes_replacedtest_10000/seq_2190...\n",
      "                              ...                        \n",
      "1970    ../../data/diseaes_replacedtest_10000/seq_1270...\n",
      "1971    ../../data/diseaes_replacedtest_10000/seq_1447...\n",
      "1972    ../../data/diseaes_replacedtest_10000/seq_1314...\n",
      "1973    ../../data/diseaes_replacedtest_10000/seq_1192...\n",
      "1974    ../../data/diseaes_replacedtest_10000/seq_1290...\n",
      "1975    ../../data/diseaes_replacedtest_10000/seq_8450...\n",
      "1976    ../../data/diseaes_replacedtest_10000/seq_9370...\n",
      "1977    ../../data/diseaes_replacedtest_10000/seq_1827...\n",
      "1978    ../../data/diseaes_replacedtest_10000/seq_50_6...\n",
      "1979    ../../data/diseaes_replacedtest_10000/seq_8390...\n",
      "1980    ../../data/diseaes_replacedtest_10000/seq_1956...\n",
      "1981    ../../data/diseaes_replacedtest_10000/seq_9810...\n",
      "1982    ../../data/diseaes_replacedtest_10000/seq_5790...\n",
      "1983    ../../data/diseaes_replacedtest_10000/seq_1229...\n",
      "1984    ../../data/diseaes_replacedtest_10000/seq_6160...\n",
      "1985    ../../data/diseaes_replacedtest_10000/seq_660_...\n",
      "1986    ../../data/diseaes_replacedtest_10000/seq_6370...\n",
      "1987    ../../data/diseaes_replacedtest_10000/seq_3880...\n",
      "1988    ../../data/diseaes_replacedtest_10000/seq_1364...\n",
      "1989    ../../data/diseaes_replacedtest_10000/seq_1287...\n",
      "1990    ../../data/diseaes_replacedtest_10000/seq_1338...\n",
      "1991    ../../data/diseaes_replacedtest_10000/seq_1430...\n",
      "1992    ../../data/diseaes_replacedtest_10000/seq_4360...\n",
      "1993    ../../data/diseaes_replacedtest_10000/seq_1792...\n",
      "1994    ../../data/diseaes_replacedtest_10000/seq_1294...\n",
      "1995    ../../data/diseaes_replacedtest_10000/seq_2270...\n",
      "1996    ../../data/diseaes_replacedtest_10000/seq_1414...\n",
      "1997    ../../data/diseaes_replacedtest_10000/seq_1980...\n",
      "1998    ../../data/diseaes_replacedtest_10000/seq_1981...\n",
      "1999    ../../data/diseaes_replacedtest_10000/seq_1136...\n",
      "Name: path, Length: 2000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "back_window = 25\n",
    "train = get_data(directory)\n",
    "X = train.path\n",
    "print(X)\n",
    "X.to_csv(directory + '/files_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "import pickle as pkl\n",
    "\n",
    "def get_seqs(path, vocab_size):\n",
    "    #print(path)\n",
    "    seq = pd.read_csv(path)\n",
    "    #print(seq.shape)\n",
    "    \n",
    "    X = []\n",
    "    decoder_target = []\n",
    "    y_time = []\n",
    "    \n",
    "    for index, row in seq.iterrows():\n",
    "        if row['fromIndex'] >= 0 and index < seq.shape[0] - 1:\n",
    "            X.append(to_categorical(seq.iloc[index+1-back_window:index+1]['InputCode'].values, \n",
    "                                    num_classes=vocab_size))\n",
    "            decoder_target.append(to_categorical(seq.iloc[index+2-back_window:index+2]['InputCode'].values, \n",
    "                                 num_classes=vocab_size))\n",
    "            y_time.append(seq.iloc[index+1]['fromIndex'])\n",
    "    \n",
    "    \n",
    "    # encoder input, decoder input, decoder target, y_time\n",
    "    return (np.asarray(X), np.asarray(X),\n",
    "            np.asarray(decoder_target), np.asarray(y_time))\n",
    "\n",
    "    \n",
    "def batch_generator(X, batch_size=32):\n",
    "    vocab_dict = pkl.load(open(directory + '/input_token_index.pkl', 'rb'))\n",
    "    vocab_size = len(vocab_dict)\n",
    "    while True:\n",
    "        # choose batch_size random images / labels from the data\n",
    "        idx = np.random.randint(0, X.shape[0], batch_size)\n",
    "        x_file = X[idx]\n",
    "        \n",
    "        if str(x_file.values[0]) == 'nan':\n",
    "            continue\n",
    "        encoder_input, decoder_input, decoder_target, y_time = get_seqs(str(x_file.values[0]), len(vocab_dict))\n",
    "        \n",
    "        for i in range(encoder_input.shape[0] / batch_size):\n",
    "            if (encoder_input.ndim == 3) and (((i+1)*batch_size)-(i*batch_size)) > 1:\n",
    "                yield ([encoder_input[(i*batch_size):(i+1)*batch_size],\n",
    "                        decoder_input[(i*batch_size):(i+1)*batch_size]], \n",
    "                       [decoder_target[(i*batch_size):(i+1)*batch_size],\n",
    "                        y_time[(i*batch_size):(i+1)*batch_size,]])\n",
    "            else:\n",
    "                pass \n",
    "#                 print(encoder_input.shape, decoder_input.shape, decoder_target.shape, y_time.shape)\n",
    "#                 print(X[idx])\n",
    "#                 raise Exception('stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.17 s, sys: 3.12 s, total: 12.3 s\n",
      "Wall time: 12.4 s\n",
      "('shapes: ', (32, 25, 1436), (32, 25, 1436), (32, 25, 1436), (32,))\n"
     ]
    }
   ],
   "source": [
    "# print(get_seqs('../../data/test_1000/seq_1200_1300.csv.gz'))\n",
    "%time [ei_batch, di_batch], [dt_batch, y_time_batch] = batch_generator(X).next()\n",
    "print('shapes: ', ei_batch.shape, di_batch.shape, dt_batch.shape, y_time_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NCCL support available\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.layers import Input, LSTM, Dense, Lambda, GRU, Embedding, GaussianNoise\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras_exp.multigpu import print_mgpu_modelsummary\n",
    "\n",
    "def get_model(num_tokens, latent_dim):\n",
    "    encoder_inputs = Input(shape=(None, num_tokens), name='encoder_input')\n",
    "    encoder = GRU(latent_dim, return_state=True, name='encoded')\n",
    "    encoder_outputs, state_h = encoder(encoder_inputs)\n",
    "                                       \n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None, num_tokens), name='decoder_input')\n",
    "    noisy_inputs = GaussianNoise(0.2)(decoder_inputs)\n",
    "    decoder_gru = GRU(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _ = decoder_gru(noisy_inputs, initial_state=state_h)\n",
    "    decoder_dense = Dense(num_tokens, activation='softmax', name='ae')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    time_internal = Dense(100, activation='relu')(encoder_outputs)\n",
    "    time_dense = Dense(1, activation='relu', name='time')\n",
    "    time_output = time_dense(time_internal)\n",
    "\n",
    "    model = Model([encoder_inputs, decoder_inputs], [decoder_outputs, time_output])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n",
      "(<class 'pandas.core.series.Series'>, 1600.0)\n",
      "(1600, 400)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      (None, None, 1436)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input (InputLayer)      (None, None, 1436)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNoise (None, None, 1436)   0           decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoded (GRU)                   [(None, 10), (None,  43410       encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     [(None, None, 10), ( 43410       gaussian_noise_1[0][0]           \n",
      "                                                                 encoded[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          1100        encoded[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ae (Dense)                      (None, None, 1436)   15796       gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time (Dense)                    (None, 1)            101         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 103,817\n",
      "Trainable params: 103,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/network.py:888: UserWarning: Layer gru_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'encoded/while/Exit_2:0' shape=(?, 10) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "print(tf.__version__)\n",
    "    \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "print(type(X), X.shape[0]*0.8)\n",
    "Xt = X[int(X.shape[0]*0.8):]\n",
    "X = X[:int(X.shape[0]*0.8)]\n",
    "\n",
    "Xt = Xt.reset_index(drop=True)\n",
    "\n",
    "print(len(X), len(Xt)) \n",
    "\n",
    "fixed_length = 25\n",
    "fixed_vocab = len(pkl.load(open(directory + '/input_token_index.pkl', 'rb')))\n",
    "# epochs = 100\n",
    "latent_dim = 10\n",
    "\n",
    "model = get_model(fixed_vocab, latent_dim)\n",
    "\n",
    "losses = {'ae':'categorical_crossentropy', 'time':'mse'}\n",
    "loss_weights = {'ae':1, 'time':2}\n",
    "earlystopper = EarlyStopping(monitor='loss', patience=100, verbose=1)\n",
    "tbCallback = TensorBoard(log_dir='../../logs/gd', write_graph=True)\n",
    "\n",
    "filepath = output_dir + \"/weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, mode='min')\n",
    "\n",
    "model.compile(optimizer='adam', loss=losses, loss_weights=loss_weights)\n",
    "model.save(output_dir + '/empty_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 400)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "train_gen = batch_generator(X, batch_size=batch_size)\n",
    "valid_gen = batch_generator(Xt, batch_size=batch_size)\n",
    "print(len(X), len(Xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/training_generator.py:44: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 1627532.2192 - ae_loss: 7.1540 - time_loss: 813762.5333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/training_generator.py:272: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 194s 2s/step - loss: 1619760.7477 - ae_loss: 7.1497 - time_loss: 809876.7998 - val_loss: 1379612.7063 - val_ae_loss: 6.8105 - val_time_loss: 689802.9437\n",
      "\n",
      "Epoch 00001: saving model to ../../outputs/test10000_gd/weights.01-1379612.71.hdf5\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 175s 2s/step - loss: 1538795.3855 - ae_loss: 6.5377 - time_loss: 769394.4263 - val_loss: 1348884.8313 - val_ae_loss: 6.4467 - val_time_loss: 674439.1930\n",
      "\n",
      "Epoch 00002: saving model to ../../outputs/test10000_gd/weights.02-1348884.83.hdf5\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 176s 2s/step - loss: 1401357.9162 - ae_loss: 6.4416 - time_loss: 700675.7404 - val_loss: 890498.7719 - val_ae_loss: 6.4131 - val_time_loss: 445246.1789\n",
      "\n",
      "Epoch 00003: saving model to ../../outputs/test10000_gd/weights.03-890498.77.hdf5\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 177s 2s/step - loss: 1384201.6782 - ae_loss: 6.4186 - time_loss: 692097.6289 - val_loss: 812559.9297 - val_ae_loss: 6.4217 - val_time_loss: 406276.7578\n",
      "\n",
      "Epoch 00004: saving model to ../../outputs/test10000_gd/weights.04-812559.93.hdf5\n",
      "Epoch 5/2000\n",
      "100/100 [==============================] - 174s 2s/step - loss: 980488.2865 - ae_loss: 6.4768 - time_loss: 490240.9057 - val_loss: 488228.5969 - val_ae_loss: 6.4727 - val_time_loss: 244111.0625\n",
      "\n",
      "Epoch 00005: saving model to ../../outputs/test10000_gd/weights.05-488228.60.hdf5\n",
      "Epoch 6/2000\n",
      "100/100 [==============================] - 172s 2s/step - loss: 854595.7300 - ae_loss: 6.4211 - time_loss: 427294.6548 - val_loss: 721262.9469 - val_ae_loss: 6.5135 - val_time_loss: 360628.2215\n",
      "\n",
      "Epoch 00006: saving model to ../../outputs/test10000_gd/weights.06-721262.95.hdf5\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 171s 2s/step - loss: 739355.5591 - ae_loss: 6.4248 - time_loss: 369674.5667 - val_loss: 627573.3672 - val_ae_loss: 6.4093 - val_time_loss: 313783.4813\n",
      "\n",
      "Epoch 00007: saving model to ../../outputs/test10000_gd/weights.07-627573.37.hdf5\n",
      "Epoch 8/2000\n",
      "100/100 [==============================] - 171s 2s/step - loss: 685695.1925 - ae_loss: 6.3761 - time_loss: 342844.4069 - val_loss: 650588.8359 - val_ae_loss: 6.4089 - val_time_loss: 325291.2156\n",
      "\n",
      "Epoch 00008: saving model to ../../outputs/test10000_gd/weights.08-650588.84.hdf5\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 172s 2s/step - loss: 664540.7330 - ae_loss: 6.3628 - time_loss: 332267.1847 - val_loss: 453785.0703 - val_ae_loss: 6.3030 - val_time_loss: 226889.3875\n",
      "\n",
      "Epoch 00009: saving model to ../../outputs/test10000_gd/weights.09-453785.07.hdf5\n",
      "Epoch 10/2000\n",
      "100/100 [==============================] - 175s 2s/step - loss: 612311.4363 - ae_loss: 6.4586 - time_loss: 306152.4900 - val_loss: 436924.1250 - val_ae_loss: 6.4120 - val_time_loss: 218458.8570\n",
      "\n",
      "Epoch 00010: saving model to ../../outputs/test10000_gd/weights.10-436924.12.hdf5\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 171s 2s/step - loss: 582341.6005 - ae_loss: 6.4210 - time_loss: 291167.5892 - val_loss: 379733.2125 - val_ae_loss: 6.3644 - val_time_loss: 189863.4219\n",
      "\n",
      "Epoch 00011: saving model to ../../outputs/test10000_gd/weights.11-379733.21.hdf5\n",
      "Epoch 12/2000\n",
      "100/100 [==============================] - 170s 2s/step - loss: 585492.4760 - ae_loss: 6.3746 - time_loss: 292743.0509 - val_loss: 541256.2672 - val_ae_loss: 6.3904 - val_time_loss: 270624.9375\n",
      "\n",
      "Epoch 00012: saving model to ../../outputs/test10000_gd/weights.12-541256.27.hdf5\n",
      "Epoch 13/2000\n",
      "100/100 [==============================] - 174s 2s/step - loss: 523045.4051 - ae_loss: 6.3781 - time_loss: 261519.5150 - val_loss: 467885.1250 - val_ae_loss: 6.3960 - val_time_loss: 233939.3641\n",
      "\n",
      "Epoch 00013: saving model to ../../outputs/test10000_gd/weights.13-467885.12.hdf5\n",
      "Epoch 14/2000\n",
      "100/100 [==============================] - 168s 2s/step - loss: 599503.5563 - ae_loss: 6.4853 - time_loss: 299748.5366 - val_loss: 570175.9938 - val_ae_loss: 6.4245 - val_time_loss: 285084.7812\n",
      "\n",
      "Epoch 00014: saving model to ../../outputs/test10000_gd/weights.14-570175.99.hdf5\n",
      "Epoch 15/2000\n",
      "100/100 [==============================] - 176s 2s/step - loss: 599320.9394 - ae_loss: 6.3928 - time_loss: 299657.2729 - val_loss: 497624.9188 - val_ae_loss: 6.3941 - val_time_loss: 248809.2633\n",
      "\n",
      "Epoch 00015: saving model to ../../outputs/test10000_gd/weights.15-497624.92.hdf5\n",
      "Epoch 16/2000\n",
      "100/100 [==============================] - 173s 2s/step - loss: 535462.7233 - ae_loss: 6.3857 - time_loss: 267728.1683 - val_loss: 517352.5219 - val_ae_loss: 6.3569 - val_time_loss: 258673.0844\n",
      "\n",
      "Epoch 00016: saving model to ../../outputs/test10000_gd/weights.16-517352.52.hdf5\n",
      "Epoch 17/2000\n",
      "100/100 [==============================] - 177s 2s/step - loss: 568971.9191 - ae_loss: 6.4059 - time_loss: 284482.7565 - val_loss: 471885.0875 - val_ae_loss: 6.4917 - val_time_loss: 235939.2969\n",
      "\n",
      "Epoch 00017: saving model to ../../outputs/test10000_gd/weights.17-471885.09.hdf5\n",
      "Epoch 18/2000\n",
      "100/100 [==============================] - 173s 2s/step - loss: 585275.8670 - ae_loss: 6.3828 - time_loss: 292634.7423 - val_loss: 485028.4313 - val_ae_loss: 6.2846 - val_time_loss: 242511.0734\n",
      "\n",
      "Epoch 00018: saving model to ../../outputs/test10000_gd/weights.18-485028.43.hdf5\n",
      "Epoch 19/2000\n",
      "100/100 [==============================] - 174s 2s/step - loss: 580075.2638 - ae_loss: 6.3874 - time_loss: 290034.4383 - val_loss: 567132.8172 - val_ae_loss: 6.4591 - val_time_loss: 283563.1758\n",
      "\n",
      "Epoch 00019: saving model to ../../outputs/test10000_gd/weights.19-567132.82.hdf5\n",
      "Epoch 20/2000\n",
      "100/100 [==============================] - 172s 2s/step - loss: 627064.7383 - ae_loss: 6.3804 - time_loss: 313529.1799 - val_loss: 478138.9594 - val_ae_loss: 6.4028 - val_time_loss: 239066.2781\n",
      "\n",
      "Epoch 00020: saving model to ../../outputs/test10000_gd/weights.20-478138.96.hdf5\n",
      "Epoch 21/2000\n",
      "100/100 [==============================] - 173s 2s/step - loss: 548904.3803 - ae_loss: 6.4101 - time_loss: 274448.9861 - val_loss: 423162.8453 - val_ae_loss: 6.4482 - val_time_loss: 211578.1953\n",
      "\n",
      "Epoch 00021: saving model to ../../outputs/test10000_gd/weights.21-423162.85.hdf5\n",
      "Epoch 22/2000\n",
      "100/100 [==============================] - 170s 2s/step - loss: 597531.8402 - ae_loss: 6.3674 - time_loss: 298762.7373 - val_loss: 424924.0250 - val_ae_loss: 6.4074 - val_time_loss: 212458.8094\n",
      "\n",
      "Epoch 00022: saving model to ../../outputs/test10000_gd/weights.22-424924.03.hdf5\n",
      "Epoch 23/2000\n",
      "100/100 [==============================] - 170s 2s/step - loss: 572461.8475 - ae_loss: 6.3823 - time_loss: 286227.7319 - val_loss: 538731.4938 - val_ae_loss: 6.4485 - val_time_loss: 269362.5234\n",
      "\n",
      "Epoch 00023: saving model to ../../outputs/test10000_gd/weights.23-538731.49.hdf5\n",
      "Epoch 24/2000\n",
      "100/100 [==============================] - 176s 2s/step - loss: 571452.0489 - ae_loss: 6.4171 - time_loss: 285722.8155 - val_loss: 417151.1922 - val_ae_loss: 6.2729 - val_time_loss: 208572.4578\n",
      "\n",
      "Epoch 00024: saving model to ../../outputs/test10000_gd/weights.24-417151.19.hdf5\n",
      "Epoch 25/2000\n",
      "100/100 [==============================] - 173s 2s/step - loss: 595456.8005 - ae_loss: 6.4081 - time_loss: 297725.1965 - val_loss: 497177.4328 - val_ae_loss: 6.3655 - val_time_loss: 248585.5336\n",
      "\n",
      "Epoch 00025: saving model to ../../outputs/test10000_gd/weights.25-497177.43.hdf5\n",
      "Epoch 26/2000\n",
      "100/100 [==============================] - 171s 2s/step - loss: 611559.2499 - ae_loss: 6.4175 - time_loss: 305776.4175 - val_loss: 611513.7547 - val_ae_loss: 6.4014 - val_time_loss: 305753.6711\n",
      "\n",
      "Epoch 00026: saving model to ../../outputs/test10000_gd/weights.26-611513.75.hdf5\n",
      "Epoch 27/2000\n",
      "100/100 [==============================] - 177s 2s/step - loss: 618657.8137 - ae_loss: 6.4137 - time_loss: 309325.6985 - val_loss: 569651.8562 - val_ae_loss: 6.4176 - val_time_loss: 284822.7203\n",
      "\n",
      "Epoch 00027: saving model to ../../outputs/test10000_gd/weights.27-569651.86.hdf5\n",
      "Epoch 28/2000\n",
      "100/100 [==============================] - 171s 2s/step - loss: 532169.8180 - ae_loss: 6.3737 - time_loss: 266081.7229 - val_loss: 575292.0437 - val_ae_loss: 6.2542 - val_time_loss: 287642.8906\n",
      "\n",
      "Epoch 00028: saving model to ../../outputs/test10000_gd/weights.28-575292.04.hdf5\n",
      "Epoch 29/2000\n",
      "100/100 [==============================] - 176s 2s/step - loss: 562058.8677 - ae_loss: 6.3746 - time_loss: 281026.2472 - val_loss: 593992.2734 - val_ae_loss: 6.5220 - val_time_loss: 296992.8750\n",
      "\n",
      "Epoch 00029: saving model to ../../outputs/test10000_gd/weights.29-593992.27.hdf5\n",
      "Epoch 30/2000\n",
      "100/100 [==============================] - 171s 2s/step - loss: 607833.0275 - ae_loss: 6.4196 - time_loss: 303913.3050 - val_loss: 477719.7625 - val_ae_loss: 6.3591 - val_time_loss: 238856.7031\n",
      "\n",
      "Epoch 00030: saving model to ../../outputs/test10000_gd/weights.30-477719.76.hdf5\n",
      "Epoch 31/2000\n",
      "100/100 [==============================] - 170s 2s/step - loss: 594875.4464 - ae_loss: 6.3750 - time_loss: 297434.5363 - val_loss: 494678.8594 - val_ae_loss: 6.4252 - val_time_loss: 247336.2203\n",
      "\n",
      "Epoch 00031: saving model to ../../outputs/test10000_gd/weights.31-494678.86.hdf5\n",
      "Epoch 32/2000\n",
      "100/100 [==============================] - 174s 2s/step - loss: 654233.0516 - ae_loss: 6.3809 - time_loss: 327113.3347 - val_loss: 714302.0547 - val_ae_loss: 6.5182 - val_time_loss: 357147.7680\n",
      "\n",
      "Epoch 00032: saving model to ../../outputs/test10000_gd/weights.32-714302.05.hdf5\n",
      "Epoch 33/2000\n",
      "100/100 [==============================] - 176s 2s/step - loss: 628877.9959 - ae_loss: 6.3798 - time_loss: 314435.8080 - val_loss: 547955.4563 - val_ae_loss: 6.3820 - val_time_loss: 273974.5391\n",
      "\n",
      "Epoch 00033: saving model to ../../outputs/test10000_gd/weights.33-547955.46.hdf5\n",
      "Epoch 34/2000\n",
      "100/100 [==============================] - 173s 2s/step - loss: 684957.3917 - ae_loss: 6.3576 - time_loss: 342475.5175 - val_loss: 574088.1531 - val_ae_loss: 6.3588 - val_time_loss: 287040.8953\n",
      "\n",
      "Epoch 00034: saving model to ../../outputs/test10000_gd/weights.34-574088.15.hdf5\n",
      "Epoch 35/2000\n",
      "100/100 [==============================] - 174s 2s/step - loss: 612053.6136 - ae_loss: 6.4075 - time_loss: 306023.6035 - val_loss: 542359.2156 - val_ae_loss: 6.3038 - val_time_loss: 271176.4562\n",
      "\n",
      "Epoch 00035: saving model to ../../outputs/test10000_gd/weights.35-542359.22.hdf5\n",
      "Epoch 36/2000\n",
      "100/100 [==============================] - 167s 2s/step - loss: 550581.4558 - ae_loss: 6.4371 - time_loss: 275287.5095 - val_loss: 425187.4656 - val_ae_loss: 6.3817 - val_time_loss: 212590.5422\n",
      "\n",
      "Epoch 00036: saving model to ../../outputs/test10000_gd/weights.36-425187.47.hdf5\n",
      "Epoch 37/2000\n",
      "100/100 [==============================] - 174s 2s/step - loss: 595212.4814 - ae_loss: 6.5805 - time_loss: 297602.9513 - val_loss: 612357.4203 - val_ae_loss: 6.3909 - val_time_loss: 306175.5109\n",
      "\n",
      "Epoch 00037: saving model to ../../outputs/test10000_gd/weights.37-612357.42.hdf5\n",
      "Epoch 38/2000\n",
      "100/100 [==============================] - 173s 2s/step - loss: 549936.1308 - ae_loss: 6.3328 - time_loss: 274964.8994 - val_loss: 598961.8562 - val_ae_loss: 6.3911 - val_time_loss: 299477.7328\n",
      "\n",
      "Epoch 00038: saving model to ../../outputs/test10000_gd/weights.38-598961.86.hdf5\n",
      "Epoch 39/2000\n",
      "100/100 [==============================] - 175s 2s/step - loss: 616013.9569 - ae_loss: 6.3272 - time_loss: 308003.8150 - val_loss: 524858.6625 - val_ae_loss: 6.4000 - val_time_loss: 262426.1328\n",
      "\n",
      "Epoch 00039: saving model to ../../outputs/test10000_gd/weights.39-524858.66.hdf5\n",
      "Epoch 40/2000\n",
      "100/100 [==============================] - 177s 2s/step - loss: 497860.7706 - ae_loss: 6.3871 - time_loss: 248927.1920 - val_loss: 468298.8891 - val_ae_loss: 6.4294 - val_time_loss: 234146.2297\n",
      "\n",
      "Epoch 00040: saving model to ../../outputs/test10000_gd/weights.40-468298.89.hdf5\n",
      "Epoch 41/2000\n",
      "100/100 [==============================] - 170s 2s/step - loss: 550146.3550 - ae_loss: 6.3371 - time_loss: 275070.0093 - val_loss: 418883.5828 - val_ae_loss: 6.3950 - val_time_loss: 209438.5914\n",
      "\n",
      "Epoch 00041: saving model to ../../outputs/test10000_gd/weights.41-418883.58.hdf5\n",
      "Epoch 42/2000\n",
      "100/100 [==============================] - 171s 2s/step - loss: 629387.8538 - ae_loss: 6.3418 - time_loss: 314690.7559 - val_loss: 470577.6625 - val_ae_loss: 6.2928 - val_time_loss: 235285.6844\n",
      "\n",
      "Epoch 00042: saving model to ../../outputs/test10000_gd/weights.42-470577.66.hdf5\n",
      "Epoch 43/2000\n",
      "100/100 [==============================] - 175s 2s/step - loss: 562033.5733 - ae_loss: 6.3190 - time_loss: 281013.6282 - val_loss: 594315.4281 - val_ae_loss: 6.2936 - val_time_loss: 297154.5687\n",
      "\n",
      "Epoch 00043: saving model to ../../outputs/test10000_gd/weights.43-594315.43.hdf5\n",
      "Epoch 44/2000\n",
      "100/100 [==============================] - 173s 2s/step - loss: 551562.0759 - ae_loss: 6.3469 - time_loss: 275777.8643 - val_loss: 607015.2469 - val_ae_loss: 6.2915 - val_time_loss: 303504.4758\n",
      "\n",
      "Epoch 00044: saving model to ../../outputs/test10000_gd/weights.44-607015.25.hdf5\n",
      "Epoch 45/2000\n",
      "100/100 [==============================] - 172s 2s/step - loss: 551320.4035 - ae_loss: 6.3830 - time_loss: 275657.0118 - val_loss: 559687.7594 - val_ae_loss: 6.2619 - val_time_loss: 279840.7484\n",
      "\n",
      "Epoch 00045: saving model to ../../outputs/test10000_gd/weights.45-559687.76.hdf5\n",
      "Epoch 46/2000\n",
      "100/100 [==============================] - 177s 2s/step - loss: 542267.3107 - ae_loss: 6.3705 - time_loss: 271130.4702 - val_loss: 468629.5609 - val_ae_loss: 6.3812 - val_time_loss: 234311.5922\n",
      "\n",
      "Epoch 00046: saving model to ../../outputs/test10000_gd/weights.46-468629.56.hdf5\n",
      "Epoch 47/2000\n",
      "100/100 [==============================] - 175s 2s/step - loss: 620979.1793 - ae_loss: 6.3369 - time_loss: 310486.4208 - val_loss: 464971.1562 - val_ae_loss: 6.3521 - val_time_loss: 232482.4023\n",
      "\n",
      "Epoch 00047: saving model to ../../outputs/test10000_gd/weights.47-464971.16.hdf5\n",
      "Epoch 48/2000\n",
      "100/100 [==============================] - 173s 2s/step - loss: 564651.1992 - ae_loss: 6.3322 - time_loss: 282322.4347 - val_loss: 290692.5141 - val_ae_loss: 6.2415 - val_time_loss: 145343.1367\n",
      "\n",
      "Epoch 00048: saving model to ../../outputs/test10000_gd/weights.48-290692.51.hdf5\n",
      "Epoch 49/2000\n",
      "100/100 [==============================] - 159s 2s/step - loss: 559523.8029 - ae_loss: 6.3422 - time_loss: 279758.7315 - val_loss: 627456.9313 - val_ae_loss: 6.3092 - val_time_loss: 313725.3156\n",
      "\n",
      "Epoch 00049: saving model to ../../outputs/test10000_gd/weights.49-627456.93.hdf5\n",
      "Epoch 50/2000\n",
      "100/100 [==============================] - 161s 2s/step - loss: 572133.4347 - ae_loss: 6.3309 - time_loss: 286063.5520 - val_loss: 400809.3594 - val_ae_loss: 6.2113 - val_time_loss: 200401.5719\n",
      "\n",
      "Epoch 00050: saving model to ../../outputs/test10000_gd/weights.50-400809.36.hdf5\n",
      "Epoch 51/2000\n",
      "100/100 [==============================] - 161s 2s/step - loss: 549630.6930 - ae_loss: 6.4043 - time_loss: 274812.1442 - val_loss: 505589.7719 - val_ae_loss: 6.1883 - val_time_loss: 252791.7906\n",
      "\n",
      "Epoch 00051: saving model to ../../outputs/test10000_gd/weights.51-505589.77.hdf5\n",
      "Epoch 52/2000\n",
      "100/100 [==============================] - 160s 2s/step - loss: 547569.5092 - ae_loss: 6.3103 - time_loss: 273781.5987 - val_loss: 333081.1766 - val_ae_loss: 6.1618 - val_time_loss: 166537.5070\n",
      "\n",
      "Epoch 00052: saving model to ../../outputs/test10000_gd/weights.52-333081.18.hdf5\n",
      "Epoch 53/2000\n",
      "100/100 [==============================] - 159s 2s/step - loss: 612538.7180 - ae_loss: 6.2787 - time_loss: 306266.2201 - val_loss: 538817.0766 - val_ae_loss: 6.2479 - val_time_loss: 269405.4125\n",
      "\n",
      "Epoch 00053: saving model to ../../outputs/test10000_gd/weights.53-538817.08.hdf5\n",
      "Epoch 54/2000\n",
      "100/100 [==============================] - 161s 2s/step - loss: 524876.2891 - ae_loss: 6.2810 - time_loss: 262435.0044 - val_loss: 534708.0813 - val_ae_loss: 6.1522 - val_time_loss: 267350.9656\n",
      "\n",
      "Epoch 00054: saving model to ../../outputs/test10000_gd/weights.54-534708.08.hdf5\n",
      "Epoch 55/2000\n",
      "100/100 [==============================] - 159s 2s/step - loss: 477962.2545 - ae_loss: 6.2588 - time_loss: 238977.9986 - val_loss: 494984.7562 - val_ae_loss: 6.2031 - val_time_loss: 247489.2750\n",
      "\n",
      "Epoch 00055: saving model to ../../outputs/test10000_gd/weights.55-494984.76.hdf5\n",
      "Epoch 56/2000\n",
      "100/100 [==============================] - 159s 2s/step - loss: 522755.0284 - ae_loss: 6.2821 - time_loss: 261374.3727 - val_loss: 540268.7906 - val_ae_loss: 6.0247 - val_time_loss: 270131.3875\n",
      "\n",
      "Epoch 00056: saving model to ../../outputs/test10000_gd/weights.56-540268.79.hdf5\n",
      "Epoch 57/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 162s 2s/step - loss: 514920.6326 - ae_loss: 6.2826 - time_loss: 257457.1754 - val_loss: 609217.3953 - val_ae_loss: 6.1834 - val_time_loss: 304605.6078\n",
      "\n",
      "Epoch 00057: saving model to ../../outputs/test10000_gd/weights.57-609217.40.hdf5\n",
      "Epoch 58/2000\n",
      "100/100 [==============================] - 157s 2s/step - loss: 522173.1850 - ae_loss: 6.2377 - time_loss: 261083.4739 - val_loss: 470564.6359 - val_ae_loss: 6.2347 - val_time_loss: 235279.2008\n",
      "\n",
      "Epoch 00058: saving model to ../../outputs/test10000_gd/weights.58-470564.64.hdf5\n",
      "Epoch 59/2000\n",
      "100/100 [==============================] - 159s 2s/step - loss: 531667.5684 - ae_loss: 6.2663 - time_loss: 265830.6506 - val_loss: 650148.4688 - val_ae_loss: 6.3580 - val_time_loss: 325071.0609\n",
      "\n",
      "Epoch 00059: saving model to ../../outputs/test10000_gd/weights.59-650148.47.hdf5\n",
      "Epoch 60/2000\n",
      "100/100 [==============================] - 158s 2s/step - loss: 539380.5681 - ae_loss: 6.2914 - time_loss: 269687.1386 - val_loss: 478541.8891 - val_ae_loss: 6.1211 - val_time_loss: 239267.8828\n",
      "\n",
      "Epoch 00060: saving model to ../../outputs/test10000_gd/weights.60-478541.89.hdf5\n",
      "Epoch 61/2000\n",
      "100/100 [==============================] - 163s 2s/step - loss: 557137.7236 - ae_loss: 6.2675 - time_loss: 278565.7273 - val_loss: 409501.3187 - val_ae_loss: 6.0907 - val_time_loss: 204747.6141\n",
      "\n",
      "Epoch 00061: saving model to ../../outputs/test10000_gd/weights.61-409501.32.hdf5\n",
      "Epoch 62/2000\n",
      "100/100 [==============================] - 160s 2s/step - loss: 566024.1269 - ae_loss: 6.2671 - time_loss: 283008.9297 - val_loss: 490919.6656 - val_ae_loss: 6.0717 - val_time_loss: 245456.7938\n",
      "\n",
      "Epoch 00062: saving model to ../../outputs/test10000_gd/weights.62-490919.67.hdf5\n",
      "Epoch 63/2000\n",
      "100/100 [==============================] - 157s 2s/step - loss: 502246.9214 - ae_loss: 6.2292 - time_loss: 251120.3465 - val_loss: 631539.7047 - val_ae_loss: 6.0982 - val_time_loss: 315766.8031\n",
      "\n",
      "Epoch 00063: saving model to ../../outputs/test10000_gd/weights.63-631539.70.hdf5\n",
      "Epoch 64/2000\n",
      "100/100 [==============================] - 160s 2s/step - loss: 585622.7864 - ae_loss: 6.2143 - time_loss: 292808.2862 - val_loss: 413699.8000 - val_ae_loss: 6.0521 - val_time_loss: 206846.8750\n",
      "\n",
      "Epoch 00064: saving model to ../../outputs/test10000_gd/weights.64-413699.80.hdf5\n",
      "Epoch 65/2000\n",
      "100/100 [==============================] - 159s 2s/step - loss: 655670.3295 - ae_loss: 6.2202 - time_loss: 327832.0537 - val_loss: 480752.5906 - val_ae_loss: 6.0314 - val_time_loss: 240373.2812\n",
      "\n",
      "Epoch 00065: saving model to ../../outputs/test10000_gd/weights.65-480752.59.hdf5\n",
      "Epoch 66/2000\n",
      "100/100 [==============================] - 160s 2s/step - loss: 542762.9627 - ae_loss: 6.1584 - time_loss: 271378.4016 - val_loss: 520484.5516 - val_ae_loss: 6.2109 - val_time_loss: 260239.1719\n",
      "\n",
      "Epoch 00066: saving model to ../../outputs/test10000_gd/weights.66-520484.55.hdf5\n",
      "Epoch 67/2000\n",
      "100/100 [==============================] - 154s 2s/step - loss: 532068.8902 - ae_loss: 6.1883 - time_loss: 266031.3507 - val_loss: 513202.3703 - val_ae_loss: 6.0192 - val_time_loss: 256598.1781\n",
      "\n",
      "Epoch 00067: saving model to ../../outputs/test10000_gd/weights.67-513202.37.hdf5\n",
      "Epoch 68/2000\n",
      "100/100 [==============================] - 157s 2s/step - loss: 502701.9111 - ae_loss: 6.2300 - time_loss: 251347.8402 - val_loss: 657547.5328 - val_ae_loss: 6.1572 - val_time_loss: 328770.6859\n",
      "\n",
      "Epoch 00068: saving model to ../../outputs/test10000_gd/weights.68-657547.53.hdf5\n",
      "Epoch 69/2000\n",
      "100/100 [==============================] - 160s 2s/step - loss: 535252.1786 - ae_loss: 6.1698 - time_loss: 267623.0045 - val_loss: 448302.3531 - val_ae_loss: 6.1270 - val_time_loss: 224148.1125\n",
      "\n",
      "Epoch 00069: saving model to ../../outputs/test10000_gd/weights.69-448302.35.hdf5\n",
      "Epoch 70/2000\n",
      "100/100 [==============================] - 160s 2s/step - loss: 519396.3267 - ae_loss: 6.2003 - time_loss: 259695.0637 - val_loss: 452069.2219 - val_ae_loss: 5.9425 - val_time_loss: 226031.6375\n",
      "\n",
      "Epoch 00070: saving model to ../../outputs/test10000_gd/weights.70-452069.22.hdf5\n",
      "Epoch 71/2000\n",
      "100/100 [==============================] - 159s 2s/step - loss: 556633.5579 - ae_loss: 6.2730 - time_loss: 278313.6417 - val_loss: 464666.5844 - val_ae_loss: 6.1292 - val_time_loss: 232330.2234\n",
      "\n",
      "Epoch 00071: saving model to ../../outputs/test10000_gd/weights.71-464666.58.hdf5\n",
      "Epoch 72/2000\n",
      "100/100 [==============================] - 159s 2s/step - loss: 530532.3540 - ae_loss: 6.2204 - time_loss: 265263.0661 - val_loss: 426211.2687 - val_ae_loss: 6.3101 - val_time_loss: 213102.4742\n",
      "\n",
      "Epoch 00072: saving model to ../../outputs/test10000_gd/weights.72-426211.27.hdf5\n",
      "Epoch 73/2000\n",
      "100/100 [==============================] - 156s 2s/step - loss: 503486.7839 - ae_loss: 6.1139 - time_loss: 251740.3357 - val_loss: 477135.0672 - val_ae_loss: 6.1459 - val_time_loss: 238564.4617\n",
      "\n",
      "Epoch 00073: saving model to ../../outputs/test10000_gd/weights.73-477135.07.hdf5\n",
      "Epoch 74/2000\n",
      "100/100 [==============================] - 159s 2s/step - loss: 541299.4361 - ae_loss: 6.1602 - time_loss: 270646.6395 - val_loss: 487196.5938 - val_ae_loss: 6.2204 - val_time_loss: 243595.1859\n",
      "\n",
      "Epoch 00074: saving model to ../../outputs/test10000_gd/weights.74-487196.59.hdf5\n",
      "Epoch 75/2000\n",
      "100/100 [==============================] - 159s 2s/step - loss: 547498.3564 - ae_loss: 6.2087 - time_loss: 273746.0745 - val_loss: 530321.6094 - val_ae_loss: 6.0673 - val_time_loss: 265157.7734\n",
      "\n",
      "Epoch 00075: saving model to ../../outputs/test10000_gd/weights.75-530321.61.hdf5\n",
      "Epoch 76/2000\n",
      "100/100 [==============================] - 159s 2s/step - loss: 459330.2008 - ae_loss: 6.2070 - time_loss: 229661.9975 - val_loss: 433210.5938 - val_ae_loss: 6.0572 - val_time_loss: 216602.2680\n",
      "\n",
      "Epoch 00076: saving model to ../../outputs/test10000_gd/weights.76-433210.59.hdf5\n",
      "Epoch 77/2000\n",
      "100/100 [==============================] - 157s 2s/step - loss: 477351.9497 - ae_loss: 6.1298 - time_loss: 238672.9094 - val_loss: 476439.5750 - val_ae_loss: 5.9957 - val_time_loss: 238216.7859\n",
      "\n",
      "Epoch 00077: saving model to ../../outputs/test10000_gd/weights.77-476439.58.hdf5\n",
      "Epoch 78/2000\n",
      "100/100 [==============================] - 154s 2s/step - loss: 501666.3452 - ae_loss: 6.1477 - time_loss: 250830.0998 - val_loss: 458792.5531 - val_ae_loss: 6.2156 - val_time_loss: 229393.1688\n",
      "\n",
      "Epoch 00078: saving model to ../../outputs/test10000_gd/weights.78-458792.55.hdf5\n",
      "Epoch 79/2000\n",
      "100/100 [==============================] - 152s 2s/step - loss: 478225.2249 - ae_loss: 6.1777 - time_loss: 239109.5240 - val_loss: 415741.5422 - val_ae_loss: 6.0975 - val_time_loss: 207867.7258\n",
      "\n",
      "Epoch 00079: saving model to ../../outputs/test10000_gd/weights.79-415741.54.hdf5\n",
      "Epoch 80/2000\n",
      "100/100 [==============================] - 152s 2s/step - loss: 496649.5115 - ae_loss: 6.1373 - time_loss: 248321.6878 - val_loss: 450560.0906 - val_ae_loss: 6.1785 - val_time_loss: 225276.9539\n",
      "\n",
      "Epoch 00080: saving model to ../../outputs/test10000_gd/weights.80-450560.09.hdf5\n",
      "Epoch 81/2000\n",
      "100/100 [==============================] - 151s 2s/step - loss: 460852.3474 - ae_loss: 6.1256 - time_loss: 230423.1120 - val_loss: 465482.9719 - val_ae_loss: 6.1180 - val_time_loss: 232738.4250\n",
      "\n",
      "Epoch 00081: saving model to ../../outputs/test10000_gd/weights.81-465482.97.hdf5\n",
      "Epoch 82/2000\n",
      "100/100 [==============================] - 155s 2s/step - loss: 556900.0312 - ae_loss: 6.1305 - time_loss: 278446.9490 - val_loss: 565728.0703 - val_ae_loss: 5.9552 - val_time_loss: 282861.0594\n",
      "\n",
      "Epoch 00082: saving model to ../../outputs/test10000_gd/weights.82-565728.07.hdf5\n",
      "Epoch 83/2000\n",
      "100/100 [==============================] - 152s 2s/step - loss: 541784.0433 - ae_loss: 6.0942 - time_loss: 270888.9750 - val_loss: 453981.1719 - val_ae_loss: 6.0748 - val_time_loss: 226987.5453\n",
      "\n",
      "Epoch 00083: saving model to ../../outputs/test10000_gd/weights.83-453981.17.hdf5\n",
      "Epoch 84/2000\n",
      "100/100 [==============================] - 153s 2s/step - loss: 497143.5840 - ae_loss: 6.1886 - time_loss: 248568.6981 - val_loss: 396511.0859 - val_ae_loss: 6.1562 - val_time_loss: 198252.4648\n",
      "\n",
      "Epoch 00084: saving model to ../../outputs/test10000_gd/weights.84-396511.09.hdf5\n",
      "Epoch 85/2000\n",
      "100/100 [==============================] - 148s 1s/step - loss: 485355.0401 - ae_loss: 6.1059 - time_loss: 242674.4668 - val_loss: 374309.5969 - val_ae_loss: 6.0735 - val_time_loss: 187151.7625\n",
      "\n",
      "Epoch 00085: saving model to ../../outputs/test10000_gd/weights.85-374309.60.hdf5\n",
      "Epoch 86/2000\n",
      "100/100 [==============================] - 158s 2s/step - loss: 515028.4215 - ae_loss: 6.1166 - time_loss: 257511.1526 - val_loss: 697880.4187 - val_ae_loss: 6.0345 - val_time_loss: 348937.1961\n",
      "\n",
      "Epoch 00086: saving model to ../../outputs/test10000_gd/weights.86-697880.42.hdf5\n",
      "Epoch 87/2000\n",
      "100/100 [==============================] - 154s 2s/step - loss: 539568.7108 - ae_loss: 6.1027 - time_loss: 269781.3047 - val_loss: 407872.7516 - val_ae_loss: 6.0972 - val_time_loss: 203933.3250\n",
      "\n",
      "Epoch 00087: saving model to ../../outputs/test10000_gd/weights.87-407872.75.hdf5\n",
      "Epoch 88/2000\n",
      "100/100 [==============================] - 157s 2s/step - loss: 488583.3601 - ae_loss: 6.1531 - time_loss: 244288.6043 - val_loss: 553839.5031 - val_ae_loss: 6.0121 - val_time_loss: 276916.7438\n",
      "\n",
      "Epoch 00088: saving model to ../../outputs/test10000_gd/weights.88-553839.50.hdf5\n",
      "Epoch 89/2000\n",
      "100/100 [==============================] - 147s 1s/step - loss: 464043.5817 - ae_loss: 6.0965 - time_loss: 232018.7431 - val_loss: 438392.2344 - val_ae_loss: 5.9783 - val_time_loss: 219193.1281\n",
      "\n",
      "Epoch 00089: saving model to ../../outputs/test10000_gd/weights.89-438392.23.hdf5\n",
      "Epoch 90/2000\n",
      "100/100 [==============================] - 152s 2s/step - loss: 509807.9887 - ae_loss: 6.1159 - time_loss: 254900.9360 - val_loss: 357970.1656 - val_ae_loss: 5.8672 - val_time_loss: 178982.1484\n",
      "\n",
      "Epoch 00090: saving model to ../../outputs/test10000_gd/weights.90-357970.17.hdf5\n",
      "Epoch 91/2000\n",
      "100/100 [==============================] - 157s 2s/step - loss: 513825.0541 - ae_loss: 6.0923 - time_loss: 256909.4811 - val_loss: 346953.8516 - val_ae_loss: 6.0523 - val_time_loss: 173473.9000\n",
      "\n",
      "Epoch 00091: saving model to ../../outputs/test10000_gd/weights.91-346953.85.hdf5\n",
      "Epoch 92/2000\n",
      "100/100 [==============================] - 155s 2s/step - loss: 480344.4822 - ae_loss: 6.1073 - time_loss: 240169.1869 - val_loss: 398608.6344 - val_ae_loss: 6.0067 - val_time_loss: 199301.3141\n",
      "\n",
      "Epoch 00092: saving model to ../../outputs/test10000_gd/weights.92-398608.63.hdf5\n",
      "Epoch 93/2000\n",
      "100/100 [==============================] - 157s 2s/step - loss: 521548.3424 - ae_loss: 6.0475 - time_loss: 260771.1479 - val_loss: 392981.1969 - val_ae_loss: 6.1004 - val_time_loss: 196487.5477\n",
      "\n",
      "Epoch 00093: saving model to ../../outputs/test10000_gd/weights.93-392981.20.hdf5\n",
      "Epoch 94/2000\n",
      "100/100 [==============================] - 152s 2s/step - loss: 488619.5029 - ae_loss: 6.0533 - time_loss: 244306.7250 - val_loss: 465678.6906 - val_ae_loss: 5.8736 - val_time_loss: 232836.4062\n",
      "\n",
      "Epoch 00094: saving model to ../../outputs/test10000_gd/weights.94-465678.69.hdf5\n",
      "Epoch 95/2000\n",
      "100/100 [==============================] - 153s 2s/step - loss: 557415.4308 - ae_loss: 6.0714 - time_loss: 278704.6802 - val_loss: 497821.9062 - val_ae_loss: 5.9815 - val_time_loss: 248907.9648\n",
      "\n",
      "Epoch 00095: saving model to ../../outputs/test10000_gd/weights.95-497821.91.hdf5\n",
      "Epoch 96/2000\n",
      "100/100 [==============================] - 151s 2s/step - loss: 486489.9611 - ae_loss: 6.1091 - time_loss: 243241.9255 - val_loss: 495314.7438 - val_ae_loss: 6.0484 - val_time_loss: 247654.3516\n",
      "\n",
      "Epoch 00096: saving model to ../../outputs/test10000_gd/weights.96-495314.74.hdf5\n",
      "Epoch 97/2000\n",
      "100/100 [==============================] - 149s 1s/step - loss: 542478.6550 - ae_loss: 6.0740 - time_loss: 271236.2907 - val_loss: 482951.5094 - val_ae_loss: 5.9730 - val_time_loss: 241472.7703\n",
      "\n",
      "Epoch 00097: saving model to ../../outputs/test10000_gd/weights.97-482951.51.hdf5\n",
      "Epoch 98/2000\n",
      "100/100 [==============================] - 152s 2s/step - loss: 519927.0056 - ae_loss: 6.0294 - time_loss: 259960.4887 - val_loss: 472144.7719 - val_ae_loss: 6.0384 - val_time_loss: 236069.3703\n",
      "\n",
      "Epoch 00098: saving model to ../../outputs/test10000_gd/weights.98-472144.77.hdf5\n",
      "Epoch 99/2000\n",
      "100/100 [==============================] - 151s 2s/step - loss: 485214.0392 - ae_loss: 6.1050 - time_loss: 242603.9668 - val_loss: 350988.4313 - val_ae_loss: 5.9290 - val_time_loss: 175491.2484\n",
      "\n",
      "Epoch 00099: saving model to ../../outputs/test10000_gd/weights.99-350988.43.hdf5\n",
      "Epoch 100/2000\n",
      "100/100 [==============================] - 153s 2s/step - loss: 459921.3009 - ae_loss: 6.0853 - time_loss: 229957.6081 - val_loss: 410649.8016 - val_ae_loss: 5.8565 - val_time_loss: 205321.9742\n",
      "\n",
      "Epoch 00100: saving model to ../../outputs/test10000_gd/weights.100-410649.80.hdf5\n",
      "Epoch 101/2000\n",
      "100/100 [==============================] - 153s 2s/step - loss: 546390.1213 - ae_loss: 6.0941 - time_loss: 273192.0144 - val_loss: 497044.1000 - val_ae_loss: 6.0974 - val_time_loss: 248519.0000\n",
      "\n",
      "Epoch 00101: saving model to ../../outputs/test10000_gd/weights.101-497044.10.hdf5\n",
      "Epoch 102/2000\n",
      "100/100 [==============================] - 153s 2s/step - loss: 497539.7162 - ae_loss: 6.0830 - time_loss: 248766.8176 - val_loss: 504963.9188 - val_ae_loss: 5.9496 - val_time_loss: 252478.9852\n",
      "\n",
      "Epoch 00102: saving model to ../../outputs/test10000_gd/weights.102-504963.92.hdf5\n",
      "Epoch 103/2000\n",
      "100/100 [==============================] - 151s 2s/step - loss: 533296.4509 - ae_loss: 6.1049 - time_loss: 266645.1743 - val_loss: 343764.5766 - val_ae_loss: 5.9835 - val_time_loss: 171879.2953\n",
      "\n",
      "Epoch 00103: saving model to ../../outputs/test10000_gd/weights.103-343764.58.hdf5\n",
      "Epoch 104/2000\n",
      "100/100 [==============================] - 152s 2s/step - loss: 555386.7265 - ae_loss: 6.0566 - time_loss: 277690.3329 - val_loss: 606941.8688 - val_ae_loss: 6.0778 - val_time_loss: 303467.8984\n",
      "\n",
      "Epoch 00104: saving model to ../../outputs/test10000_gd/weights.104-606941.87.hdf5\n",
      "Epoch 105/2000\n",
      "100/100 [==============================] - 156s 2s/step - loss: 493171.0025 - ae_loss: 6.0685 - time_loss: 246582.4647 - val_loss: 480204.8172 - val_ae_loss: 6.0357 - val_time_loss: 240099.3914\n",
      "\n",
      "Epoch 00105: saving model to ../../outputs/test10000_gd/weights.105-480204.82.hdf5\n",
      "Epoch 106/2000\n",
      "100/100 [==============================] - 153s 2s/step - loss: 562869.4492 - ae_loss: 6.1483 - time_loss: 281431.6505 - val_loss: 428554.3625 - val_ae_loss: 5.9587 - val_time_loss: 214274.2000\n",
      "\n",
      "Epoch 00106: saving model to ../../outputs/test10000_gd/weights.106-428554.36.hdf5\n",
      "Epoch 107/2000\n",
      "100/100 [==============================] - 152s 2s/step - loss: 511227.6814 - ae_loss: 6.0498 - time_loss: 255610.8149 - val_loss: 333351.0344 - val_ae_loss: 5.9544 - val_time_loss: 166672.5375\n",
      "\n",
      "Epoch 00107: saving model to ../../outputs/test10000_gd/weights.107-333351.03.hdf5\n",
      "Epoch 108/2000\n",
      "100/100 [==============================] - 152s 2s/step - loss: 429702.9876 - ae_loss: 5.9997 - time_loss: 214848.4935 - val_loss: 439026.0578 - val_ae_loss: 6.0047 - val_time_loss: 219510.0258\n",
      "\n",
      "Epoch 00108: saving model to ../../outputs/test10000_gd/weights.108-439026.06.hdf5\n",
      "Epoch 109/2000\n",
      "100/100 [==============================] - 160s 2s/step - loss: 515140.7766 - ae_loss: 6.1161 - time_loss: 257567.3305 - val_loss: 585489.9125 - val_ae_loss: 5.9841 - val_time_loss: 292741.9648\n",
      "\n",
      "Epoch 00109: saving model to ../../outputs/test10000_gd/weights.109-585489.91.hdf5\n",
      "Epoch 110/2000\n",
      "100/100 [==============================] - 155s 2s/step - loss: 477891.3323 - ae_loss: 6.0360 - time_loss: 238942.6469 - val_loss: 626256.5687 - val_ae_loss: 6.0362 - val_time_loss: 313125.2633\n",
      "\n",
      "Epoch 00110: saving model to ../../outputs/test10000_gd/weights.110-626256.57.hdf5\n",
      "Epoch 111/2000\n",
      "100/100 [==============================] - 151s 2s/step - loss: 514859.7080 - ae_loss: 6.0473 - time_loss: 257426.8300 - val_loss: 496707.6344 - val_ae_loss: 5.8284 - val_time_loss: 248350.9016\n",
      "\n",
      "Epoch 00111: saving model to ../../outputs/test10000_gd/weights.111-496707.63.hdf5\n",
      "Epoch 112/2000\n",
      "100/100 [==============================] - 153s 2s/step - loss: 561455.3532 - ae_loss: 6.0328 - time_loss: 280724.6586 - val_loss: 422805.7266 - val_ae_loss: 5.8228 - val_time_loss: 211399.9516\n",
      "\n",
      "Epoch 00112: saving model to ../../outputs/test10000_gd/weights.112-422805.73.hdf5\n",
      "Epoch 113/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 153s 2s/step - loss: 439043.4677 - ae_loss: 6.0255 - time_loss: 219518.7198 - val_loss: 470264.7469 - val_ae_loss: 5.9736 - val_time_loss: 235129.3844\n",
      "\n",
      "Epoch 00113: saving model to ../../outputs/test10000_gd/weights.113-470264.75.hdf5\n",
      "Epoch 114/2000\n",
      "100/100 [==============================] - 155s 2s/step - loss: 577380.7698 - ae_loss: 6.0507 - time_loss: 288687.3597 - val_loss: 436523.4000 - val_ae_loss: 6.0881 - val_time_loss: 218258.6562\n",
      "\n",
      "Epoch 00114: saving model to ../../outputs/test10000_gd/weights.114-436523.40.hdf5\n",
      "Epoch 115/2000\n",
      "100/100 [==============================] - 153s 2s/step - loss: 506308.1648 - ae_loss: 6.0969 - time_loss: 253151.0354 - val_loss: 539267.4750 - val_ae_loss: 6.0801 - val_time_loss: 269630.6984\n",
      "\n",
      "Epoch 00115: saving model to ../../outputs/test10000_gd/weights.115-539267.47.hdf5\n",
      "Epoch 116/2000\n",
      "100/100 [==============================] - 154s 2s/step - loss: 518750.4729 - ae_loss: 6.0192 - time_loss: 259372.2286 - val_loss: 368031.4781 - val_ae_loss: 5.8445 - val_time_loss: 184012.8164\n",
      "\n",
      "Epoch 00116: saving model to ../../outputs/test10000_gd/weights.116-368031.48.hdf5\n",
      "Epoch 117/2000\n",
      "100/100 [==============================] - 153s 2s/step - loss: 452563.3545 - ae_loss: 6.0482 - time_loss: 226278.6530 - val_loss: 401375.5172 - val_ae_loss: 5.7586 - val_time_loss: 200684.8828\n",
      "\n",
      "Epoch 00117: saving model to ../../outputs/test10000_gd/weights.117-401375.52.hdf5\n",
      "Epoch 118/2000\n",
      "100/100 [==============================] - 154s 2s/step - loss: 508373.3738 - ae_loss: 5.9501 - time_loss: 254183.7122 - val_loss: 515382.6688 - val_ae_loss: 5.9923 - val_time_loss: 257688.3398\n",
      "\n",
      "Epoch 00171: saving model to ../../outputs/test10000_gd/weights.171-515382.67.hdf5\n",
      "Epoch 172/2000\n",
      "100/100 [==============================] - 151s 2s/step - loss: 450760.5912 - ae_loss: 5.9835 - time_loss: 225377.3033 - val_loss: 570534.4641 - val_ae_loss: 5.8263 - val_time_loss: 285264.3172\n",
      "\n",
      "Epoch 00172: saving model to ../../outputs/test10000_gd/weights.172-570534.46.hdf5\n",
      "Epoch 173/2000\n",
      "100/100 [==============================] - 152s 2s/step - loss: 494812.7252 - ae_loss: 5.8985 - time_loss: 247403.4128 - val_loss: 330755.5531 - val_ae_loss: 5.8611 - val_time_loss: 165374.8469\n",
      "\n",
      "Epoch 00173: saving model to ../../outputs/test10000_gd/weights.173-330755.55.hdf5\n",
      "Epoch 174/2000\n",
      "100/100 [==============================] - 149s 1s/step - loss: 479800.6227 - ae_loss: 5.9817 - time_loss: 239897.3205 - val_loss: 501326.1594 - val_ae_loss: 5.8519 - val_time_loss: 250660.1500\n",
      "\n",
      "Epoch 00174: saving model to ../../outputs/test10000_gd/weights.174-501326.16.hdf5\n",
      "Epoch 175/2000\n",
      "100/100 [==============================] - 149s 1s/step - loss: 503217.6037 - ae_loss: 6.0243 - time_loss: 251605.7909 - val_loss: 328682.6609 - val_ae_loss: 5.9412 - val_time_loss: 164338.3578\n",
      "\n",
      "Epoch 00175: saving model to ../../outputs/test10000_gd/weights.175-328682.66.hdf5\n",
      "Epoch 176/2000\n",
      "100/100 [==============================] - 151s 2s/step - loss: 532108.3546 - ae_loss: 5.9588 - time_loss: 266051.1985 - val_loss: 383979.5766 - val_ae_loss: 5.8431 - val_time_loss: 191986.8656\n",
      "\n",
      "Epoch 00176: saving model to ../../outputs/test10000_gd/weights.176-383979.58.hdf5\n",
      "Epoch 177/2000\n",
      "100/100 [==============================] - 154s 2s/step - loss: 491012.9273 - ae_loss: 6.0254 - time_loss: 245503.4520 - val_loss: 469501.9750 - val_ae_loss: 5.8103 - val_time_loss: 234748.0820\n",
      "\n",
      "Epoch 00177: saving model to ../../outputs/test10000_gd/weights.177-469501.97.hdf5\n",
      "Epoch 178/2000\n",
      "100/100 [==============================] - 149s 1s/step - loss: 529035.5641 - ae_loss: 5.9920 - time_loss: 264514.7871 - val_loss: 489316.2812 - val_ae_loss: 5.6514 - val_time_loss: 244655.3141\n",
      "\n",
      "Epoch 00178: saving model to ../../outputs/test10000_gd/weights.178-489316.28.hdf5\n",
      "Epoch 179/2000\n",
      "100/100 [==============================] - 152s 2s/step - loss: 459680.5358 - ae_loss: 5.8936 - time_loss: 229837.3208 - val_loss: 439662.5359 - val_ae_loss: 5.7196 - val_time_loss: 219828.4070\n",
      "\n",
      "Epoch 00179: saving model to ../../outputs/test10000_gd/weights.179-439662.54.hdf5\n",
      "Epoch 180/2000\n",
      "100/100 [==============================] - 157s 2s/step - loss: 565127.6258 - ae_loss: 6.0106 - time_loss: 282560.8081 - val_loss: 466255.0109 - val_ae_loss: 5.8921 - val_time_loss: 233124.5625\n",
      "\n",
      "Epoch 00180: saving model to ../../outputs/test10000_gd/weights.180-466255.01.hdf5\n",
      "Epoch 181/2000\n",
      "100/100 [==============================] - 153s 2s/step - loss: 526553.9163 - ae_loss: 5.9686 - time_loss: 263273.9752 - val_loss: 446973.1219 - val_ae_loss: 5.8348 - val_time_loss: 223483.6437\n",
      "\n",
      "Epoch 00181: saving model to ../../outputs/test10000_gd/weights.181-446973.12.hdf5\n",
      "Epoch 182/2000\n",
      "100/100 [==============================] - 150s 2s/step - loss: 463605.0040 - ae_loss: 5.9649 - time_loss: 231799.5186 - val_loss: 443387.8344 - val_ae_loss: 5.8101 - val_time_loss: 221691.0109\n",
      "\n",
      "Epoch 00182: saving model to ../../outputs/test10000_gd/weights.182-443387.83.hdf5\n",
      "Epoch 183/2000\n",
      "100/100 [==============================] - 150s 1s/step - loss: 494180.9820 - ae_loss: 5.9788 - time_loss: 247087.5018 - val_loss: 352738.7094 - val_ae_loss: 5.7831 - val_time_loss: 176366.4641\n",
      "\n",
      "Epoch 00183: saving model to ../../outputs/test10000_gd/weights.183-352738.71.hdf5\n",
      "Epoch 184/2000\n",
      "100/100 [==============================] - 154s 2s/step - loss: 426809.9920 - ae_loss: 5.9934 - time_loss: 213401.9991 - val_loss: 474079.4281 - val_ae_loss: 5.8588 - val_time_loss: 237036.7844\n",
      "\n",
      "Epoch 00184: saving model to ../../outputs/test10000_gd/weights.184-474079.43.hdf5\n",
      "Epoch 185/2000\n",
      "100/100 [==============================] - 155s 2s/step - loss: 455738.5415 - ae_loss: 5.9377 - time_loss: 227866.3014 - val_loss: 413023.1656 - val_ae_loss: 5.7326 - val_time_loss: 206508.7156\n",
      "\n",
      "Epoch 00185: saving model to ../../outputs/test10000_gd/weights.185-413023.17.hdf5\n",
      "Epoch 186/2000\n",
      "100/100 [==============================] - 154s 2s/step - loss: 551045.3259 - ae_loss: 6.0217 - time_loss: 275519.6516 - val_loss: 360155.3344 - val_ae_loss: 5.7309 - val_time_loss: 180074.8008\n",
      "\n",
      "Epoch 00186: saving model to ../../outputs/test10000_gd/weights.186-360155.33.hdf5\n",
      "Epoch 187/2000\n",
      "100/100 [==============================] - 151s 2s/step - loss: 493031.0646 - ae_loss: 5.9348 - time_loss: 246512.5658 - val_loss: 476709.1437 - val_ae_loss: 5.8219 - val_time_loss: 238351.6617\n",
      "\n",
      "Epoch 00187: saving model to ../../outputs/test10000_gd/weights.187-476709.14.hdf5\n",
      "Epoch 188/2000\n",
      "100/100 [==============================] - 152s 2s/step - loss: 509451.6080 - ae_loss: 5.9693 - time_loss: 254722.8180 - val_loss: 546226.5188 - val_ae_loss: 5.7027 - val_time_loss: 273110.4078\n",
      "\n",
      "Epoch 00188: saving model to ../../outputs/test10000_gd/weights.188-546226.52.hdf5\n",
      "Epoch 189/2000\n",
      "100/100 [==============================] - 151s 2s/step - loss: 468260.4073 - ae_loss: 5.9513 - time_loss: 234127.2288 - val_loss: 412423.5172 - val_ae_loss: 5.9278 - val_time_loss: 206208.7906\n",
      "\n",
      "Epoch 00189: saving model to ../../outputs/test10000_gd/weights.189-412423.52.hdf5\n",
      "Epoch 190/2000\n",
      "100/100 [==============================] - 153s 2s/step - loss: 499673.9554 - ae_loss: 5.9282 - time_loss: 249834.0129 - val_loss: 528807.5148 - val_ae_loss: 5.6728 - val_time_loss: 264400.9242\n",
      "\n",
      "Epoch 00190: saving model to ../../outputs/test10000_gd/weights.190-528807.51.hdf5\n",
      "Epoch 191/2000\n",
      "100/100 [==============================] - 151s 2s/step - loss: 457788.7187 - ae_loss: 5.9233 - time_loss: 228891.3978 - val_loss: 435071.6375 - val_ae_loss: 5.9348 - val_time_loss: 217532.8484\n",
      "\n",
      "Epoch 00191: saving model to ../../outputs/test10000_gd/weights.191-435071.64.hdf5\n",
      "Epoch 192/2000\n",
      "100/100 [==============================] - 152s 2s/step - loss: 458503.3240 - ae_loss: 5.9228 - time_loss: 229248.7010 - val_loss: 422491.2797 - val_ae_loss: 5.7422 - val_time_loss: 211242.7695\n",
      "\n",
      "Epoch 00192: saving model to ../../outputs/test10000_gd/weights.192-422491.28.hdf5\n",
      "Epoch 193/2000\n",
      "100/100 [==============================] - 158s 2s/step - loss: 520583.6955 - ae_loss: 5.9669 - time_loss: 260288.8654 - val_loss: 541819.3187 - val_ae_loss: 6.0005 - val_time_loss: 270906.6578\n",
      "\n",
      "Epoch 00193: saving model to ../../outputs/test10000_gd/weights.193-541819.32.hdf5\n",
      "Epoch 194/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 150s 2s/step - loss: 502348.4740 - ae_loss: 5.9858 - time_loss: 251171.2450 - val_loss: 430953.2641 - val_ae_loss: 5.8163 - val_time_loss: 215473.7266\n",
      "\n",
      "Epoch 00194: saving model to ../../outputs/test10000_gd/weights.194-430953.26.hdf5\n",
      "Epoch 195/2000\n",
      "100/100 [==============================] - 156s 2s/step - loss: 493524.5300 - ae_loss: 5.9639 - time_loss: 246759.2839 - val_loss: 557420.6687 - val_ae_loss: 5.9186 - val_time_loss: 278707.3703\n",
      "\n",
      "Epoch 00195: saving model to ../../outputs/test10000_gd/weights.195-557420.67.hdf5\n",
      "Epoch 196/2000\n",
      "100/100 [==============================] - 149s 1s/step - loss: 507062.3654 - ae_loss: 5.9008 - time_loss: 253528.2330 - val_loss: 507968.6219 - val_ae_loss: 5.9106 - val_time_loss: 253981.3570\n",
      "\n",
      "Epoch 00196: saving model to ../../outputs/test10000_gd/weights.196-507968.62.hdf5\n",
      "Epoch 197/2000\n",
      "100/100 [==============================] - 150s 2s/step - loss: 449541.1234 - ae_loss: 5.9519 - time_loss: 224767.5861 - val_loss: 460534.8266 - val_ae_loss: 5.8635 - val_time_loss: 230264.4805\n",
      "\n",
      "Epoch 00197: saving model to ../../outputs/test10000_gd/weights.197-460534.83.hdf5\n",
      "Epoch 198/2000\n",
      "100/100 [==============================] - 152s 2s/step - loss: 545832.2938 - ae_loss: 5.9404 - time_loss: 272913.1763 - val_loss: 387659.9891 - val_ae_loss: 5.8202 - val_time_loss: 193827.0828\n",
      "\n",
      "Epoch 00198: saving model to ../../outputs/test10000_gd/weights.198-387659.99.hdf5\n",
      "Epoch 199/2000\n",
      "100/100 [==============================] - 149s 1s/step - loss: 464801.2187 - ae_loss: 5.9539 - time_loss: 232397.6324 - val_loss: 572179.4250 - val_ae_loss: 5.8441 - val_time_loss: 286086.7922\n",
      "\n",
      "Epoch 00199: saving model to ../../outputs/test10000_gd/weights.199-572179.43.hdf5\n",
      "Epoch 200/2000\n",
      "100/100 [==============================] - 153s 2s/step - loss: 483973.2559 - ae_loss: 5.9610 - time_loss: 241983.6471 - val_loss: 382838.9656 - val_ae_loss: 5.7924 - val_time_loss: 191416.5883\n",
      "\n",
      "Epoch 00200: saving model to ../../outputs/test10000_gd/weights.200-382838.97.hdf5\n",
      "Epoch 201/2000\n",
      "100/100 [==============================] - 148s 1s/step - loss: 523789.1222 - ae_loss: 5.9529 - time_loss: 261891.5852 - val_loss: 340296.2734 - val_ae_loss: 5.7639 - val_time_loss: 170145.2563\n",
      "\n",
      "Epoch 00201: saving model to ../../outputs/test10000_gd/weights.201-340296.27.hdf5\n",
      "Epoch 202/2000\n",
      "100/100 [==============================] - 160s 2s/step - loss: 408535.4919 - ae_loss: 5.9767 - time_loss: 204264.7580 - val_loss: 438146.9516 - val_ae_loss: 5.7641 - val_time_loss: 219070.5922\n",
      "\n",
      "Epoch 00202: saving model to ../../outputs/test10000_gd/weights.202-438146.95.hdf5\n",
      "Epoch 203/2000\n",
      "100/100 [==============================] - 151s 2s/step - loss: 497978.6366 - ae_loss: 5.9013 - time_loss: 248986.3675 - val_loss: 389959.6063 - val_ae_loss: 5.9312 - val_time_loss: 194976.8344\n",
      "\n",
      "Epoch 00203: saving model to ../../outputs/test10000_gd/weights.203-389959.61.hdf5\n",
      "Epoch 204/2000\n",
      "100/100 [==============================] - 150s 2s/step - loss: 510622.6515 - ae_loss: 5.8993 - time_loss: 255308.3738 - val_loss: 440714.0859 - val_ae_loss: 5.8164 - val_time_loss: 220354.1344\n",
      "\n",
      "Epoch 00204: saving model to ../../outputs/test10000_gd/weights.204-440714.09.hdf5\n",
      "Epoch 205/2000\n",
      "100/100 [==============================] - 155s 2s/step - loss: 485224.5195 - ae_loss: 5.9271 - time_loss: 242609.2961 - val_loss: 457506.0594 - val_ae_loss: 5.8698 - val_time_loss: 228750.0930\n",
      "\n",
      "Epoch 00205: saving model to ../../outputs/test10000_gd/weights.205-457506.06.hdf5\n",
      "Epoch 206/2000\n",
      "100/100 [==============================] - 152s 2s/step - loss: 491916.3778 - ae_loss: 5.9035 - time_loss: 245955.2360 - val_loss: 399110.4188 - val_ae_loss: 5.8210 - val_time_loss: 199552.2984\n",
      "\n",
      "Epoch 00206: saving model to ../../outputs/test10000_gd/weights.206-399110.42.hdf5\n",
      "Epoch 207/2000\n",
      "100/100 [==============================] - 150s 2s/step - loss: 500212.1712 - ae_loss: 5.9743 - time_loss: 250103.0981 - val_loss: 536578.7781 - val_ae_loss: 5.7916 - val_time_loss: 268286.4859\n",
      "\n",
      "Epoch 00207: saving model to ../../outputs/test10000_gd/weights.207-536578.78.hdf5\n",
      "Epoch 208/2000\n",
      "100/100 [==============================] - 153s 2s/step - loss: 470402.6259 - ae_loss: 5.9109 - time_loss: 235198.3580 - val_loss: 350500.4344 - val_ae_loss: 5.7509 - val_time_loss: 175247.3422\n",
      "\n",
      "Epoch 00208: saving model to ../../outputs/test10000_gd/weights.208-350500.43.hdf5\n",
      "Epoch 209/2000\n",
      "100/100 [==============================] - 150s 1s/step - loss: 499399.5398 - ae_loss: 6.0124 - time_loss: 249696.7638 - val_loss: 678013.5813 - val_ae_loss: 5.9384 - val_time_loss: 339003.8172\n",
      "\n",
      "Epoch 00209: saving model to ../../outputs/test10000_gd/weights.209-678013.58.hdf5\n",
      "Epoch 210/2000\n",
      "100/100 [==============================] - 150s 2s/step - loss: 480293.6380 - ae_loss: 5.9395 - time_loss: 240143.8495 - val_loss: 707103.9328 - val_ae_loss: 5.9795 - val_time_loss: 353548.9734\n",
      "\n",
      "Epoch 00210: saving model to ../../outputs/test10000_gd/weights.210-707103.93.hdf5\n",
      "Epoch 211/2000\n",
      "100/100 [==============================] - 156s 2s/step - loss: 419090.7156 - ae_loss: 5.9224 - time_loss: 209542.3974 - val_loss: 353562.1844 - val_ae_loss: 5.7599 - val_time_loss: 176778.2102\n",
      "\n",
      "Epoch 00211: saving model to ../../outputs/test10000_gd/weights.211-353562.18.hdf5\n",
      "Epoch 212/2000\n",
      "100/100 [==============================] - 150s 2s/step - loss: 502976.3262 - ae_loss: 5.9027 - time_loss: 251485.2098 - val_loss: 468132.5281 - val_ae_loss: 5.7248 - val_time_loss: 234063.4031\n",
      "\n",
      "Epoch 00212: saving model to ../../outputs/test10000_gd/weights.212-468132.53.hdf5\n",
      "Epoch 213/2000\n",
      "100/100 [==============================] - 155s 2s/step - loss: 455098.3298 - ae_loss: 5.9532 - time_loss: 227546.1877 - val_loss: 482584.6937 - val_ae_loss: 5.8231 - val_time_loss: 241289.4344\n",
      "\n",
      "Epoch 00213: saving model to ../../outputs/test10000_gd/weights.213-482584.69.hdf5\n",
      "Epoch 214/2000\n",
      "100/100 [==============================] - 152s 2s/step - loss: 503656.9162 - ae_loss: 5.8631 - time_loss: 251825.5262 - val_loss: 548280.2891 - val_ae_loss: 5.9122 - val_time_loss: 274137.1922\n",
      "\n",
      "Epoch 00214: saving model to ../../outputs/test10000_gd/weights.214-548280.29.hdf5\n",
      "Epoch 215/2000\n",
      "100/100 [==============================] - 156s 2s/step - loss: 518522.3419 - ae_loss: 5.9284 - time_loss: 259258.2057 - val_loss: 403511.0953 - val_ae_loss: 5.8895 - val_time_loss: 201752.6016\n",
      "\n",
      "Epoch 00215: saving model to ../../outputs/test10000_gd/weights.215-403511.10.hdf5\n",
      "Epoch 216/2000\n",
      "100/100 [==============================] - 153s 2s/step - loss: 502378.1838 - ae_loss: 6.0073 - time_loss: 251186.0886 - val_loss: 451587.2094 - val_ae_loss: 5.7924 - val_time_loss: 225790.7070\n",
      "\n",
      "Epoch 00216: saving model to ../../outputs/test10000_gd/weights.216-451587.21.hdf5\n",
      "Epoch 217/2000\n",
      "100/100 [==============================] - 155s 2s/step - loss: 461433.5648 - ae_loss: 5.9386 - time_loss: 230713.8127 - val_loss: 487003.8516 - val_ae_loss: 5.8468 - val_time_loss: 243499.0016\n",
      "\n",
      "Epoch 00217: saving model to ../../outputs/test10000_gd/weights.217-487003.85.hdf5\n",
      "Epoch 218/2000\n",
      "100/100 [==============================] - 154s 2s/step - loss: 448098.0142 - ae_loss: 5.8820 - time_loss: 224046.0664 - val_loss: 410900.3719 - val_ae_loss: 5.7644 - val_time_loss: 205447.3031\n",
      "\n",
      "Epoch 00218: saving model to ../../outputs/test10000_gd/weights.218-410900.37.hdf5\n",
      "Epoch 219/2000\n",
      "100/100 [==============================] - 154s 2s/step - loss: 486352.8561 - ae_loss: 6.0176 - time_loss: 243173.4198 - val_loss: 454886.6844 - val_ae_loss: 5.8522 - val_time_loss: 227440.4125\n",
      "\n",
      "Epoch 00219: saving model to ../../outputs/test10000_gd/weights.219-454886.68.hdf5\n",
      "Epoch 220/2000\n",
      "100/100 [==============================] - 153s 2s/step - loss: 536008.8447 - ae_loss: 5.8975 - time_loss: 268001.4739 - val_loss: 522503.6500 - val_ae_loss: 5.7626 - val_time_loss: 261248.9438\n",
      "\n",
      "Epoch 00220: saving model to ../../outputs/test10000_gd/weights.220-522503.65.hdf5\n",
      "Epoch 221/2000\n",
      "100/100 [==============================] - 154s 2s/step - loss: 481551.2033 - ae_loss: 6.0654 - time_loss: 240772.5684 - val_loss: 549161.5062 - val_ae_loss: 5.7648 - val_time_loss: 274577.8703\n",
      "\n",
      "Epoch 00221: saving model to ../../outputs/test10000_gd/weights.221-549161.51.hdf5\n",
      "Epoch 222/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 159s 2s/step - loss: 491762.9982 - ae_loss: 5.8830 - time_loss: 245878.5584 - val_loss: 357360.0297 - val_ae_loss: 5.7467 - val_time_loss: 178677.1414\n",
      "\n",
      "Epoch 00222: saving model to ../../outputs/test10000_gd/weights.222-357360.03.hdf5\n",
      "Epoch 223/2000\n",
      "100/100 [==============================] - 158s 2s/step - loss: 538079.3893 - ae_loss: 5.9761 - time_loss: 269036.7079 - val_loss: 367672.6227 - val_ae_loss: 5.7093 - val_time_loss: 183833.4570\n",
      "\n",
      "Epoch 00223: saving model to ../../outputs/test10000_gd/weights.223-367672.62.hdf5\n",
      "Epoch 224/2000\n",
      "100/100 [==============================] - 154s 2s/step - loss: 504074.2978 - ae_loss: 5.9476 - time_loss: 252034.1759 - val_loss: 501397.5312 - val_ae_loss: 5.9189 - val_time_loss: 250695.8062\n",
      "\n",
      "Epoch 00224: saving model to ../../outputs/test10000_gd/weights.224-501397.53.hdf5\n",
      "Epoch 225/2000\n",
      "100/100 [==============================] - 153s 2s/step - loss: 466134.9270 - ae_loss: 5.9156 - time_loss: 233064.5054 - val_loss: 440027.1125 - val_ae_loss: 5.8298 - val_time_loss: 220010.6406\n",
      "\n",
      "Epoch 00225: saving model to ../../outputs/test10000_gd/weights.225-440027.11.hdf5\n",
      "Epoch 226/2000\n",
      "100/100 [==============================] - 163s 2s/step - loss: 491718.6438 - ae_loss: 5.8831 - time_loss: 245856.3802 - val_loss: 387034.8203 - val_ae_loss: 5.8858 - val_time_loss: 193514.4672\n",
      "\n",
      "Epoch 00226: saving model to ../../outputs/test10000_gd/weights.226-387034.82.hdf5\n",
      "Epoch 227/2000\n",
      "100/100 [==============================] - 159s 2s/step - loss: 475140.9177 - ae_loss: 5.9028 - time_loss: 237567.5068 - val_loss: 342703.9437 - val_ae_loss: 5.7926 - val_time_loss: 171349.0766\n",
      "\n",
      "Epoch 00227: saving model to ../../outputs/test10000_gd/weights.227-342703.94.hdf5\n",
      "Epoch 228/2000\n",
      "100/100 [==============================] - 158s 2s/step - loss: 546633.0048 - ae_loss: 5.9286 - time_loss: 273313.5391 - val_loss: 515563.9562 - val_ae_loss: 5.8337 - val_time_loss: 257779.0602\n",
      "\n",
      "Epoch 00228: saving model to ../../outputs/test10000_gd/weights.228-515563.96.hdf5\n",
      "Epoch 229/2000\n",
      "100/100 [==============================] - 161s 2s/step - loss: 440307.4134 - ae_loss: 5.9632 - time_loss: 220150.7267 - val_loss: 427755.5672 - val_ae_loss: 5.8207 - val_time_loss: 213874.8750\n",
      "\n",
      "Epoch 00229: saving model to ../../outputs/test10000_gd/weights.229-427755.57.hdf5\n",
      "Epoch 230/2000\n",
      "100/100 [==============================] - 167s 2s/step - loss: 509951.9672 - ae_loss: 5.9414 - time_loss: 254973.0123 - val_loss: 364209.2531 - val_ae_loss: 5.9079 - val_time_loss: 182101.6719\n",
      "\n",
      "Epoch 00230: saving model to ../../outputs/test10000_gd/weights.230-364209.25.hdf5\n",
      "Epoch 231/2000\n",
      "100/100 [==============================] - 161s 2s/step - loss: 416751.3434 - ae_loss: 5.9387 - time_loss: 208372.7023 - val_loss: 287186.2109 - val_ae_loss: 5.6591 - val_time_loss: 143590.2773\n",
      "\n",
      "Epoch 00231: saving model to ../../outputs/test10000_gd/weights.231-287186.21.hdf5\n",
      "Epoch 232/2000\n",
      "100/100 [==============================] - 164s 2s/step - loss: 529541.8995 - ae_loss: 5.9702 - time_loss: 264767.9645 - val_loss: 526012.0156 - val_ae_loss: 5.9943 - val_time_loss: 263003.0125\n",
      "\n",
      "Epoch 00232: saving model to ../../outputs/test10000_gd/weights.232-526012.02.hdf5\n",
      "Epoch 00232: early stopping\n",
      "36693.48545\n"
     ]
    }
   ],
   "source": [
    "## import time\n",
    "start_time = time.time()\n",
    "model.fit_generator(\n",
    "    generator=train_gen,\n",
    "    validation_data=valid_gen,\n",
    "    validation_steps=10,\n",
    "    epochs=2000,\n",
    "    steps_per_epoch=100, #X.shape[0], - we do smaller steps per epoch to see training progress\n",
    "    use_multiprocessing = True,\n",
    "    workers = 8,\n",
    "    callbacks=[earlystopper, checkpoint, tbCallback])\n",
    "print(time.time()-start_time)\n",
    "\n",
    "model.save(output_dir + '/trained_model_weights.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py27",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
